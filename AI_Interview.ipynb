{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GzAPjqZZfsl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PRuHv71fV0jW",
        "outputId": "61867c00-4d91-4174-db54-284771ee4852"
      },
      "outputs": [],
      "source": [
        "# pip install langchain-community langchain-chroma sentence-transformers pypdf mistralai langchain faiss-cpu pypdf sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ahmX2cKnVzqq"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Admin\\Downloads\\Git_Clone\\AI-Tools\\AI_Interview\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
            "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n",
            "c:\\Users\\Admin\\Downloads\\Git_Clone\\AI-Tools\\AI_Interview\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from mistralai import Mistral\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()               # reads .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Key fetched\n"
          ]
        }
      ],
      "source": [
        "api_key = os.getenv(\"MISTRAL_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing MISTRAL_KEY in .env\")\n",
        "else:\n",
        "    print('Key fetched')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AiKISMRTYj6q"
      },
      "outputs": [],
      "source": [
        "client = Mistral(api_key=api_key)\n",
        "MODEL = \"mistral-small-latest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "VjFTBVzrbste"
      },
      "outputs": [],
      "source": [
        "# --------- Load PDFs ----------\n",
        "def load_pdf(path):\n",
        "    loader = PyPDFLoader(path)\n",
        "    return loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ekbr6zMqbtUD"
      },
      "outputs": [],
      "source": [
        "def rag_impl(resume_docs, jd_docs):\n",
        "    # 1. Direct Comparison for Match (More accurate than RAG)\n",
        "    full_resume_text = \"\\n\".join([d.page_content for d in resume_docs])\n",
        "    full_jd_text = \"\\n\".join([d.page_content for d in jd_docs])\n",
        "    \n",
        "    print(\"‚è≥ Analyzing match...\")\n",
        "    match_pct = get_match_percentage(full_resume_text, full_jd_text)\n",
        "    print(f\"\\nüéØ Resume‚ÄìJD Match: {match_pct}%\")\n",
        "\n",
        "    if match_pct < 60:\n",
        "        print(\"‚ùå Match below 60%. Candidate rejected.\")\n",
        "        return\n",
        "\n",
        "    # 2. RAG only for deep question generation\n",
        "    print(\"‚úÖ Match confirmed. Indexing documents for questions...\")\n",
        "    documents = resume_docs + jd_docs\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    chunks = splitter.split_documents(documents)\n",
        "    \n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10}) # Increased k for better context\n",
        "\n",
        "    questions = generate_questions(retriever)\n",
        "    print(\"\\n--- Generated Interview Questions ---\")\n",
        "    print(questions)\n",
        "\n",
        "def get_match_percentage(resume_text, jd_text):\n",
        "    # Clean up the prompt to handle full texts\n",
        "    prompt = f\"\"\"\n",
        "    You are a professional ATS (Applicant Tracking System).\n",
        "    \n",
        "    TASK:\n",
        "    1. Analyze the RESUME and JOB DESCRIPTION provided below.\n",
        "    2. Calculate a match percentage (0-100) based on:\n",
        "       - Technical Skills & Tools\n",
        "       - Years of Experience\n",
        "       - Project Relevance\n",
        "    \n",
        "    RESUME:\n",
        "    ---\n",
        "    {resume_text}\n",
        "    ---\n",
        "\n",
        "    JOB DESCRIPTION:\n",
        "    ---\n",
        "    {jd_text}\n",
        "    ---\n",
        "\n",
        "    OUTPUT INSTRUCTIONS:\n",
        "    Output ONLY the numerical value between 0 and 100. Do not include words or symbols.\n",
        "    \"\"\"\n",
        "    response = client.chat.complete(\n",
        "        model=MODEL,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "    )\n",
        "    # Basic cleaning to ensure it's a number\n",
        "    res_content = response.choices[0].message.content.strip().replace('%', '')\n",
        "    try:\n",
        "        return float(res_content)\n",
        "    except:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PWg-cDuQYvpb"
      },
      "outputs": [],
      "source": [
        "# --------- Match Percentage Prompt ----------\n",
        "MATCH_PROMPT = \"\"\"\n",
        "You are an ATS system.\n",
        "\n",
        "Given the CONTEXT below (resume + job description):\n",
        "1. Calculate percentage match between resume and JD.\n",
        "2. Consider skills, experience, tools, projects.\n",
        "3. Output ONLY a number between 0 and 100.\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OAW_KnHAZCQy"
      },
      "outputs": [],
      "source": [
        "# --------- Question Generation Prompt ----------\n",
        "QUESTION_PROMPT = \"\"\"\n",
        "You are a technical interviewer.\n",
        "\n",
        "Using the CONTEXT:\n",
        "- Job description requirements\n",
        "- Skills mentioned in resume\n",
        "- Projects done by candidate\n",
        "\n",
        "Generate:\n",
        "1. 5 technical questions on the job description\n",
        "2. 3 project-based questions on the projects done by candidate\n",
        "3. 2 skill-based questions on the skills mentioned in resume\n",
        "3. 2 scenario-based questions based on the job description\n",
        "\n",
        "CONTEXT:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Yac4M5V-ZExB"
      },
      "outputs": [],
      "source": [
        "def generate_questions(retriever):\n",
        "    docs = retriever.invoke(\"skills projects requirements\")\n",
        "    context = \"\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "    response = client.chat.complete(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": QUESTION_PROMPT.format(context=context)}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937,
          "referenced_widgets": [
            "ef6de7e6bffc47bb9559ff62dac196c2",
            "dc26092d681846719b03874fd3b9a2e5",
            "71bc660c43a54997b3d1d605f7a72bbb",
            "87343ba9c5924708864b71d162b53d6b",
            "fb254f775d0a4ea3bef6df4d76706a61",
            "0f5ac1b7fd9743b5b86020467869cc3b",
            "c5b16317bca3494783b6513dd7d1ddc9",
            "44ca4329e10c4586906b0f21b52e4654",
            "248fa2bc1ea54888bca9a0d8145b5e6c",
            "70c83d120cca4b89ba6040c488b90823",
            "5edbc25f8a2a4ce4bc35d6e12946e59c"
          ]
        },
        "id": "IoKm8MkoVmw9",
        "outputId": "6af882a4-ea48-4975-f829-cc7768182dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "in main\n",
            "Documents fetched!\n",
            "‚è≥ Analyzing match...\n",
            "\n",
            "üéØ Resume‚ÄìJD Match: 85.0%\n",
            "‚úÖ Match confirmed. Indexing documents for questions...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17104\\382602341.py:20: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 387.71it/s, Materializing param=pooler.dense.weight]                             \n",
            "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Generated Interview Questions ---\n",
            "Here are the tailored interview questions based on the provided context:\n",
            "\n",
            "### **1. 5 Technical Questions (Job Description Focused)**\n",
            "1. **NLP/ML Models**: Can you explain how you would design a machine learning system for summarizing unstructured data into a human-readable format? What challenges might arise, and how would you address them?\n",
            "2. **Data Processing**: How do you handle data cleaning and feature engineering when dealing with billions of data points? What tools or techniques do you use?\n",
            "3. **Model Training & Optimization**: How do you ensure optimal performance in your ML models? Walk us through your approach to training, retraining, and fine-tuning.\n",
            "4. **Knowledge Extraction**: What techniques or algorithms would you use for knowledge extraction from unstructured data? Have you worked with RAGs or Agentic AI in this context?\n",
            "5. **Data Visualization**: How do you present complex AI/ML results to non-technical stakeholders? What tools (e.g., Tableau, PowerPoint) do you prefer, and why?\n",
            "\n",
            "---\n",
            "\n",
            "### **2. 3 Project-Based Questions (Candidate‚Äôs Projects)**\n",
            "1. **ML Model Development**: You mentioned designing and training your own ML models. Can you describe one such project? What problem did it solve, and what was the outcome?\n",
            "2. **Client Collaboration**: In your role at Factspan, you worked with clients to understand use cases. Can you share an example where you had to adapt your approach based on client feedback?\n",
            "3. **Data Analysis & Visualization**: How did you use SQL, Tableau, or Excel to extract, manipulate, and visualize data in your projects? Can you walk us through a specific case?\n",
            "\n",
            "---\n",
            "\n",
            "### **3. 2 Skill-Based Questions (Resume Skills)**\n",
            "1. **Python & AI/ML Libraries**: You‚Äôve worked with Python, PyTorch, and Keras. Can you explain a scenario where you had to choose between these frameworks for a project? What was your decision-making process?\n",
            "2. **Natural Language Processing (NLP)**: You mentioned experience with NLP. How would you approach building a model for semantic search or summarization? What challenges have you faced?\n",
            "\n",
            "---\n",
            "\n",
            "### **4. 2 Scenario-Based Questions (Job Description Focused)**\n",
            "1. **Deadline Management**: You‚Äôre given a tight deadline to deliver an AI model for a client. The initial results are underperforming. How do you prioritize tasks to meet the deadline without compromising quality?\n",
            "2. **Client Communication**: A client is unhappy with the AI-generated summaries, claiming they lack context. How would you address their concerns and improve the model?\n",
            "\n",
            "These questions assess technical depth, problem-solving, client collaboration, and adaptability‚Äîkey traits for the role.\n",
            "\n",
            "Processing...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --------- Pipeline ----------\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    print('in main')\n",
        "\n",
        "  # Get file paths from user\n",
        "    resume_path = r'C:\\Users\\Admin\\Downloads\\Git_Clone\\AI-Tools\\AI_Interview\\data\\Rajat__Sharma_AI_ML.pdf' # input(\"Enter resume PDF path (e.g. Rajat__Sharma_AI_ML.pdf): \").strip()\n",
        "    jd_path = r'C:\\Users\\Admin\\Downloads\\Git_Clone\\AI-Tools\\AI_Interview\\data\\JD_ML.pdf' # input(\"Enter Job Description PDF path: \").strip()\n",
        "\n",
        "    # Loading pdf files\n",
        "    resume_docs = load_pdf(resume_path)\n",
        "    jd_docs = load_pdf(jd_path)\n",
        "\n",
        "    print('Documents fetched!')\n",
        "\n",
        "    # Calling\n",
        "    rag_impl(resume_docs, jd_docs)\n",
        "\n",
        "    print(\"\\nProcessing...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAQR6EMyfnw-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f5ac1b7fd9743b5b86020467869cc3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "248fa2bc1ea54888bca9a0d8145b5e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44ca4329e10c4586906b0f21b52e4654": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5edbc25f8a2a4ce4bc35d6e12946e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70c83d120cca4b89ba6040c488b90823": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71bc660c43a54997b3d1d605f7a72bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44ca4329e10c4586906b0f21b52e4654",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248fa2bc1ea54888bca9a0d8145b5e6c",
            "value": 103
          }
        },
        "87343ba9c5924708864b71d162b53d6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c83d120cca4b89ba6040c488b90823",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5edbc25f8a2a4ce4bc35d6e12946e59c",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá439.49it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "c5b16317bca3494783b6513dd7d1ddc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc26092d681846719b03874fd3b9a2e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f5ac1b7fd9743b5b86020467869cc3b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c5b16317bca3494783b6513dd7d1ddc9",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "ef6de7e6bffc47bb9559ff62dac196c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc26092d681846719b03874fd3b9a2e5",
              "IPY_MODEL_71bc660c43a54997b3d1d605f7a72bbb",
              "IPY_MODEL_87343ba9c5924708864b71d162b53d6b"
            ],
            "layout": "IPY_MODEL_fb254f775d0a4ea3bef6df4d76706a61"
          }
        },
        "fb254f775d0a4ea3bef6df4d76706a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
